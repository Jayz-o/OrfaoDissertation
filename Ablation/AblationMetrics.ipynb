{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarred/anaconda3/envs/Orfao_Masters/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/tmp/ipykernel_1561637/384288019.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import  tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tqdm.autonotebook import  tqdm\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from Antispoofing.SIWAntispoof.siw_antispoof_helper import get_siw_stratified_name_list_func, get_siw_protocol_frame_dic\n",
    "from Antispoofing.AntispoofHelpers.dataset_helper import get_test_generator, get_antispoof_frame\n",
    "from Antispoofing.SIWAntispoof.siw_antispoof_helper import get_siw_train_frame_func\n",
    "import pandas as pd\n",
    "from Antispoofing.AntispoofHelpers.hyper_perameter_helper import combine_with_augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 17:23:31.472900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.473095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.476601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.476746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.476875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.477001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.477324: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-29 17:23:31.626709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.626877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.627012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.627134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.627254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:31.627378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:32.080369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:32.080554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:32.080690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:32.080824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:32.080950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:32.081081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21413 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0b:00.0, compute capability: 8.6\n",
      "2022-10-29 17:23:32.081356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-29 17:23:32.081460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 8091 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "inception_model = tf.keras.applications.InceptionV3(include_top=False,\n",
    "                              weights=\"imagenet\",\n",
    "                              pooling='avg')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def compute_embeddings(data_loader_1, data_loader_2):\n",
    "    def _compute_embeddings(dataloader):\n",
    "        # for _ in tqdm(range(count)):\n",
    "        #     images = next(iter(dataloader))\n",
    "        step_size = dataloader.n // dataloader.batch_size\n",
    "        embeddings = inception_model.predict(dataloader, step_size, verbose=1)\n",
    "\n",
    "            # image_embeddings.extend(embeddings)\n",
    "\n",
    "        # return np.array(image_embeddings)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "    # compute embeddings for real images\n",
    "    data_loader_1_embeddings = _compute_embeddings(data_loader_1)\n",
    "\n",
    "    # compute embeddings for generated images\n",
    "    data_loader_2_embeddings = _compute_embeddings(data_loader_2)\n",
    "\n",
    "    print(data_loader_1_embeddings.shape,\" \", data_loader_2_embeddings.shape)\n",
    "    return data_loader_1_embeddings, data_loader_2_embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "def calculate_fid(real_embeddings, generated_embeddings):\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = real_embeddings.mean(axis=0), np.cov(real_embeddings, rowvar=False)\n",
    "    mu2, sigma2 = generated_embeddings.mean(axis=0), np.cov(generated_embeddings,  rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = linalg.sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "\n",
    "    return fid\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def calculate_set_distance(set_1_df_file_path_frame, set_2_df_file_path_frame):\n",
    "\n",
    "    if set_1_df_file_path_frame.shape[0]> set_2_df_file_path_frame.shape[0]:\n",
    "        set_1_df_file_path_frame = set_1_df_file_path_frame[:set_2_df_file_path_frame.shape[0]]\n",
    "    elif set_1_df_file_path_frame.shape[0]< set_2_df_file_path_frame.shape[0]:\n",
    "        set_2_df_file_path_frame = set_2_df_file_path_frame[:set_1_df_file_path_frame.shape[0]]\n",
    "\n",
    "    set_1_generator = get_test_generator(set_1_df_file_path_frame)\n",
    "    set_2_generator = get_test_generator(set_2_df_file_path_frame)\n",
    "\n",
    "    set_1_embeddings, set_2_embeddings = compute_embeddings(set_1_generator, set_2_generator)\n",
    "\n",
    "    return calculate_fid(set_1_embeddings, set_2_embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "test_subject_number = 90\n",
    "ATTACK_TYPE_COMBINATIONS = [\n",
    "     'A@ASUS-IP7P-IPP2017,A@N',\n",
    "     'A@ASUS-IP7P-SGS8,A@N',\n",
    "     'A@ASUS-IPP2017-SGS8,A@N',\n",
    "     'A@IP7P-IPP2017-SGS8,A@N',\n",
    "     'A@P,A@N',\n",
    "     'A@R,A@N',\n",
    "]\n",
    "\n",
    "dataset_root = \"/home/jarred/Documents/Datasets/SIW\"\n",
    "\n",
    "dataset_csv_name = \"siw.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "     usage_type ground_truth  subject_number       video_name  frames_present  \\\n2037       test         real              75  075-1-1-1-1.mov             718   \n2038       test         real              75  075-2-1-2-2.mov            1386   \n2039       test         real              75  075-2-1-1-1.mov            1487   \n2040       test         real              75  075-2-1-1-2.mov            1582   \n2041       test         real              75  075-1-1-2-1.mov             864   \n\n      video_frames attack_category            directory_path  sensor_id  \\\n2037         718.0               N  test/real/75/075-1-1-1-1          1   \n2038        1386.0               N  test/real/75/075-2-1-2-2          2   \n2039        1487.0               N  test/real/75/075-2-1-1-1          2   \n2040        1582.0               N  test/real/75/075-2-1-1-2          2   \n2041         864.0               N  test/real/75/075-1-1-2-1          1   \n\n               sensor_name  type_id type_name  medium_id medium_name  \\\n2037          Canon_EOS_T6        1      Live          1         NLV   \n2038  Logitech_C920_Webcam        1      Live          2         ELV   \n2039  Logitech_C920_Webcam        1      Live          1         NLV   \n2040  Logitech_C920_Webcam        1      Live          1         NLV   \n2041          Canon_EOS_T6        1      Live          2         ELV   \n\n      session_id session_name  \n2037           1          MBF  \n2038           2       YARFEC  \n2039           1          MBF  \n2040           2       YARFEC  \n2041           1          MBF  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usage_type</th>\n      <th>ground_truth</th>\n      <th>subject_number</th>\n      <th>video_name</th>\n      <th>frames_present</th>\n      <th>video_frames</th>\n      <th>attack_category</th>\n      <th>directory_path</th>\n      <th>sensor_id</th>\n      <th>sensor_name</th>\n      <th>type_id</th>\n      <th>type_name</th>\n      <th>medium_id</th>\n      <th>medium_name</th>\n      <th>session_id</th>\n      <th>session_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2037</th>\n      <td>test</td>\n      <td>real</td>\n      <td>75</td>\n      <td>075-1-1-1-1.mov</td>\n      <td>718</td>\n      <td>718.0</td>\n      <td>N</td>\n      <td>test/real/75/075-1-1-1-1</td>\n      <td>1</td>\n      <td>Canon_EOS_T6</td>\n      <td>1</td>\n      <td>Live</td>\n      <td>1</td>\n      <td>NLV</td>\n      <td>1</td>\n      <td>MBF</td>\n    </tr>\n    <tr>\n      <th>2038</th>\n      <td>test</td>\n      <td>real</td>\n      <td>75</td>\n      <td>075-2-1-2-2.mov</td>\n      <td>1386</td>\n      <td>1386.0</td>\n      <td>N</td>\n      <td>test/real/75/075-2-1-2-2</td>\n      <td>2</td>\n      <td>Logitech_C920_Webcam</td>\n      <td>1</td>\n      <td>Live</td>\n      <td>2</td>\n      <td>ELV</td>\n      <td>2</td>\n      <td>YARFEC</td>\n    </tr>\n    <tr>\n      <th>2039</th>\n      <td>test</td>\n      <td>real</td>\n      <td>75</td>\n      <td>075-2-1-1-1.mov</td>\n      <td>1487</td>\n      <td>1487.0</td>\n      <td>N</td>\n      <td>test/real/75/075-2-1-1-1</td>\n      <td>2</td>\n      <td>Logitech_C920_Webcam</td>\n      <td>1</td>\n      <td>Live</td>\n      <td>1</td>\n      <td>NLV</td>\n      <td>1</td>\n      <td>MBF</td>\n    </tr>\n    <tr>\n      <th>2040</th>\n      <td>test</td>\n      <td>real</td>\n      <td>75</td>\n      <td>075-2-1-1-2.mov</td>\n      <td>1582</td>\n      <td>1582.0</td>\n      <td>N</td>\n      <td>test/real/75/075-2-1-1-2</td>\n      <td>2</td>\n      <td>Logitech_C920_Webcam</td>\n      <td>1</td>\n      <td>Live</td>\n      <td>1</td>\n      <td>NLV</td>\n      <td>2</td>\n      <td>YARFEC</td>\n    </tr>\n    <tr>\n      <th>2041</th>\n      <td>test</td>\n      <td>real</td>\n      <td>75</td>\n      <td>075-1-1-2-1.mov</td>\n      <td>864</td>\n      <td>864.0</td>\n      <td>N</td>\n      <td>test/real/75/075-1-1-2-1</td>\n      <td>1</td>\n      <td>Canon_EOS_T6</td>\n      <td>1</td>\n      <td>Live</td>\n      <td>2</td>\n      <td>ELV</td>\n      <td>1</td>\n      <td>MBF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoof_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {75} and ground_truth == 'spoof'\")\n",
    "spoof_df.head()\n",
    "\n",
    "real_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {75} and ground_truth == 'real'\")\n",
    "real_df.head()\n",
    "fid = calculate_set_distance(real_df, spoof_df)\n",
    "print(round(fid, 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from Antispoofing.AntispoofHelpers.dataset_helper import get_dataframe_by_attack_category, get_dataframe_by_medium_name\n",
    "\n",
    "\n",
    "def get_category_frame(frame, categories):\n",
    "    attack_frames = []\n",
    "    for attack_type in categories:\n",
    "        if attack_type == \"P\" or attack_type == \"R\":\n",
    "            attack_frames.append(get_dataframe_by_attack_category(frame, attack_type))\n",
    "        else:\n",
    "            attack_frames.append(get_dataframe_by_medium_name(frame, attack_type))\n",
    "\n",
    "    return pd.concat(attack_frames)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10644 validated image filenames belonging to 2 classes.\n",
      "Found 10644 validated image filenames belonging to 2 classes.\n",
      "333/333 [==============================] - 42s 127ms/step\n",
      "333/333 [==============================] - 34s 101ms/step\n",
      "(10644, 2048)   (10644, 2048)\n",
      "205196.95\n"
     ]
    }
   ],
   "source": [
    "spoof_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {90} and ground_truth == 'spoof'\")\n",
    "\n",
    "\n",
    "real_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {90} and ground_truth == 'real'\")\n",
    "\n",
    "\n",
    "\n",
    "test_real_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {75} and ground_truth == 'real'\")\n",
    "\n",
    "test_spoof_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {75} and ground_truth == 'spoof'\")\n",
    "\n",
    "\n",
    "spoof_df = get_category_frame(spoof_df, [ \"P\"])\n",
    "test_spoof_df = get_category_frame(test_spoof_df, [ \"ASUS\", \"IP7P\", \"IPP2017\", \"SGS8\"])\n",
    "\n",
    "\n",
    "\n",
    "# spoof_df = get_category_frame(spoof_df, [\"ASUS\", \"IP7P\", \"IPP2017\", \"SGS8\"])\n",
    "# spoof_df = get_category_frame(spoof_df, [ \"IP7P\", \"IPP2017\", \"SGS8\"])\n",
    "# spoof_df = get_category_frame(spoof_df, [\"P\"])\n",
    "# spoof_df = get_category_frame(spoof_df, [\"ASUS\", \"IP7P\", \"IPP2017\"])\n",
    "\n",
    "train_proto = pd.concat([spoof_df, real_df])\n",
    "test_proto = pd.concat([test_spoof_df, test_real_df])\n",
    "\n",
    "fid = calculate_set_distance(train_proto, test_proto)\n",
    "print(round(fid, 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "spoof_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {90} and ground_truth == 'spoof'\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "     usage_type ground_truth  subject_number       video_name  frames_present  \\\n1086       test        spoof              90  090-1-2-2-2.mov             391   \n1087       test        spoof              90  090-1-2-1-2.mov             663   \n1088       test        spoof              90  090-1-2-1-1.mov             466   \n1091       test        spoof              90  090-1-2-2-1.mov             405   \n\n      video_frames attack_category             directory_path  sensor_id  \\\n1086         391.0               P  test/spoof/90/090-1-2-2-2          1   \n1087         663.0               P  test/spoof/90/090-1-2-1-2          1   \n1088         466.0               P  test/spoof/90/090-1-2-1-1          1   \n1091         405.0               P  test/spoof/90/090-1-2-2-1          1   \n\n       sensor_name  type_id type_name  medium_id medium_name  session_id  \\\n1086  Canon_EOS_T6        2     Print          2          LR           2   \n1087  Canon_EOS_T6        2     Print          1          HR           2   \n1088  Canon_EOS_T6        2     Print          1          HR           1   \n1091  Canon_EOS_T6        2     Print          2          LR           1   \n\n     session_name  \n1086           MP  \n1087           MP  \n1088           GP  \n1091           GP  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>usage_type</th>\n      <th>ground_truth</th>\n      <th>subject_number</th>\n      <th>video_name</th>\n      <th>frames_present</th>\n      <th>video_frames</th>\n      <th>attack_category</th>\n      <th>directory_path</th>\n      <th>sensor_id</th>\n      <th>sensor_name</th>\n      <th>type_id</th>\n      <th>type_name</th>\n      <th>medium_id</th>\n      <th>medium_name</th>\n      <th>session_id</th>\n      <th>session_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1086</th>\n      <td>test</td>\n      <td>spoof</td>\n      <td>90</td>\n      <td>090-1-2-2-2.mov</td>\n      <td>391</td>\n      <td>391.0</td>\n      <td>P</td>\n      <td>test/spoof/90/090-1-2-2-2</td>\n      <td>1</td>\n      <td>Canon_EOS_T6</td>\n      <td>2</td>\n      <td>Print</td>\n      <td>2</td>\n      <td>LR</td>\n      <td>2</td>\n      <td>MP</td>\n    </tr>\n    <tr>\n      <th>1087</th>\n      <td>test</td>\n      <td>spoof</td>\n      <td>90</td>\n      <td>090-1-2-1-2.mov</td>\n      <td>663</td>\n      <td>663.0</td>\n      <td>P</td>\n      <td>test/spoof/90/090-1-2-1-2</td>\n      <td>1</td>\n      <td>Canon_EOS_T6</td>\n      <td>2</td>\n      <td>Print</td>\n      <td>1</td>\n      <td>HR</td>\n      <td>2</td>\n      <td>MP</td>\n    </tr>\n    <tr>\n      <th>1088</th>\n      <td>test</td>\n      <td>spoof</td>\n      <td>90</td>\n      <td>090-1-2-1-1.mov</td>\n      <td>466</td>\n      <td>466.0</td>\n      <td>P</td>\n      <td>test/spoof/90/090-1-2-1-1</td>\n      <td>1</td>\n      <td>Canon_EOS_T6</td>\n      <td>2</td>\n      <td>Print</td>\n      <td>1</td>\n      <td>HR</td>\n      <td>1</td>\n      <td>GP</td>\n    </tr>\n    <tr>\n      <th>1091</th>\n      <td>test</td>\n      <td>spoof</td>\n      <td>90</td>\n      <td>090-1-2-2-1.mov</td>\n      <td>405</td>\n      <td>405.0</td>\n      <td>P</td>\n      <td>test/spoof/90/090-1-2-2-1</td>\n      <td>1</td>\n      <td>Canon_EOS_T6</td>\n      <td>2</td>\n      <td>Print</td>\n      <td>2</td>\n      <td>LR</td>\n      <td>1</td>\n      <td>GP</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = get_category_frame(spoof_df, [\"P\"])\n",
    "temp.head(30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11204 validated image filenames belonging to 2 classes.\n",
      "Found 11204 validated image filenames belonging to 2 classes.\n",
      "351/351 [==============================] - 45s 128ms/step\n",
      "351/351 [==============================] - 36s 103ms/step\n",
      "(11204, 2048)   (11204, 2048)\n",
      "Aug %:  0.05  FID:  200043.27\n",
      "Found 11827 validated image filenames belonging to 2 classes.\n",
      "Found 11827 validated image filenames belonging to 2 classes.\n",
      "370/370 [==============================] - 46s 125ms/step\n",
      "370/370 [==============================] - 37s 101ms/step\n",
      "(11827, 2048)   (11827, 2048)\n",
      "Aug %:  0.1  FID:  195497.31\n",
      "Found 13305 validated image filenames belonging to 2 classes.\n",
      "Found 13305 validated image filenames belonging to 2 classes.\n",
      "416/416 [==============================] - 47s 114ms/step\n",
      "416/416 [==============================] - 43s 104ms/step\n",
      "(13305, 2048)   (13305, 2048)\n",
      "Aug %:  0.2  FID:  187180.36\n",
      "Found 15147 validated image filenames belonging to 2 classes.\n",
      "Found 15147 validated image filenames belonging to 2 classes.\n",
      "474/474 [==============================] - 54s 113ms/step\n",
      "474/474 [==============================] - 50s 105ms/step\n",
      "(15147, 2048)   (15147, 2048)\n",
      "Aug %:  0.3  FID:  180412.16\n"
     ]
    }
   ],
   "source": [
    "train_spoof_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {90} and ground_truth == 'spoof'\")\n",
    "\n",
    "\n",
    "train_real_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {90} and ground_truth == 'real'\")\n",
    "\n",
    "test_real_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {75} and ground_truth == 'real'\")\n",
    "\n",
    "test_spoof_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {75} and ground_truth == 'spoof'\")\n",
    "\n",
    "TRAIN_SPOOF_COMBINATIONS = [\n",
    "         [  \"IP7P\", \"IPP2017\", \"SGS8\"],\n",
    "        [ \"ASUS\",  \"IPP2017\", \"SGS8\"],\n",
    "        [ \"ASUS\", \"IP7P\", \"SGS8\"],\n",
    "    [ \"ASUS\", \"IP7P\", \"IPP2017\"],\n",
    "\n",
    "    [ \"ASUS\", \"IP7P\", \"IPP2017\", \"SGS8\"],\n",
    "    [ \"P\"],\n",
    "]\n",
    "TEST_SPOOF_COMBINATIONS = [\n",
    "    [ \"ASUS\"],\n",
    "    [ \"IP7P\"],\n",
    "    [ \"IPP2017\"],\n",
    "    [ \"SGS8\"],\n",
    "    [ \"P\"],\n",
    "    [ \"ASUS\", \"IP7P\", \"IPP2017\", \"SGS8\"],\n",
    "]\n",
    "for i in range(len(TRAIN_SPOOF_COMBINATIONS)):\n",
    "    train_spoof_combination = TRAIN_SPOOF_COMBINATIONS[i]\n",
    "    test_spoof_combination = TEST_SPOOF_COMBINATIONS[i]\n",
    "\n",
    "    current_train_spoof_df = get_category_frame(train_spoof_df,train_spoof_combination)\n",
    "    current_test_spoof_df = get_category_frame(test_spoof_df,  test_spoof_combination)\n",
    "\n",
    "    # combine train spoof and real\n",
    "    current_train_spoof_df = pd.concat([current_train_spoof_df, train_real_df])\n",
    "    current_test_spoof_df = pd.concat([current_test_spoof_df, test_real_df])\n",
    "\n",
    "\n",
    "    current_train_spoof_file_path_frame = get_antispoof_frame(current_train_spoof_df, dataset_root)\n",
    "    current_test_spoof_file_path_frame = get_antispoof_frame(current_test_spoof_df, dataset_root)\n",
    "\n",
    "    current_test_spoof_file_path_frame = current_test_spoof_file_path_frame.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    use_last_only = False\n",
    "    must_remove_normal = True\n",
    "    must_use_normal_only=False\n",
    "\n",
    "    aug_root =\"/home/jarred/Documents/TraditionalAugmentation/SIW_90\"\n",
    "    aug_csv =\"SIW_90.csv\"\n",
    "    # aug_root =\"/home/jarred/Documents/Generated/SIW_KF_90\"\n",
    "    # aug_csv =\"SIW_KF_90.csv\"\n",
    "\n",
    "\n",
    "    aug_frame = pd.read_csv(os.path.join(aug_root, aug_csv))\n",
    "    AUG_PERCENTAGES = [0.05,0.1,0.2, 0.30]\n",
    "\n",
    "    fid_values ={}\n",
    "    for aug_percentage in AUG_PERCENTAGES:\n",
    "        current_aug_frame = combine_with_augmentation(train_frame= current_train_spoof_file_path_frame, aug_frame= aug_frame,aug_root= aug_root,categories= train_spoof_combination, aug_percentage=aug_percentage,must_remove_normal= must_remove_normal,must_use_normal_only=must_use_normal_only, stratified_name_list_func=None)\n",
    "\n",
    "        current_train_aug_spoof_file_path_frame = pd.concat([current_train_spoof_file_path_frame, current_aug_frame])\n",
    "        current_train_aug_spoof_file_path_frame = current_train_aug_spoof_file_path_frame.sample(frac=1).reset_index(drop=True)\n",
    "        fid = calculate_set_distance(current_train_aug_spoof_file_path_frame, current_test_spoof_file_path_frame)\n",
    "        fid_values[aug_percentage] = round(fid, 2)\n",
    "        print(\"Aug %: \", aug_percentage, \" FID: \", round(fid, 2))\n",
    "\n",
    "\n",
    "# spoof_df = get_category_frame(spoof_df, [\"ASUS\", \"IP7P\", \"IPP2017\", \"SGS8\"])\n",
    "# spoof_df = get_category_frame(spoof_df, [ \"IP7P\", \"IPP2017\", \"SGS8\"])\n",
    "# spoof_df = get_category_frame(spoof_df, [\"P\"])\n",
    "# spoof_df = get_category_frame(spoof_df, [\"ASUS\", \"IP7P\", \"IPP2017\"])\n",
    "\n",
    "\n",
    "# test_proto = pd.concat([test_spoof_df, test_real_df])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4736 validated image filenames belonging to 1 classes.\n",
      "Found 4736 validated image filenames belonging to 1 classes.\n",
      "148/148 [==============================] - 18s 119ms/step\n",
      "148/148 [==============================] - 18s 120ms/step\n",
      "(4736, 2048)   (4736, 2048)\n",
      "Aug %:  0.05  FID:  42658.06\n",
      "Found 5000 validated image filenames belonging to 1 classes.\n",
      "Found 5000 validated image filenames belonging to 1 classes.\n",
      "157/157 [==============================] - 17s 111ms/step\n",
      "157/157 [==============================] - 19s 119ms/step\n",
      "(5000, 2048)   (5000, 2048)\n",
      "Aug %:  0.1  FID:  43594.0\n",
      "Found 5624 validated image filenames belonging to 1 classes.\n",
      "Found 5624 validated image filenames belonging to 1 classes.\n",
      "176/176 [==============================] - 19s 109ms/step\n",
      "176/176 [==============================] - 21s 118ms/step\n",
      "(5624, 2048)   (5624, 2048)\n",
      "Aug %:  0.2  FID:  45688.5\n",
      "Found 6428 validated image filenames belonging to 1 classes.\n",
      "Found 6428 validated image filenames belonging to 1 classes.\n",
      "201/201 [==============================] - 21s 104ms/step\n",
      "201/201 [==============================] - 24s 120ms/step\n",
      "(6428, 2048)   (6428, 2048)\n",
      "Aug %:  0.3  FID:  47888.4\n",
      "Found 4728 validated image filenames belonging to 1 classes.\n",
      "Found 4728 validated image filenames belonging to 1 classes.\n",
      "148/148 [==============================] - 16s 107ms/step\n",
      "148/148 [==============================] - 17s 118ms/step\n",
      "(4728, 2048)   (4728, 2048)\n",
      "Aug %:  0.05  FID:  34143.03\n",
      "Found 4989 validated image filenames belonging to 1 classes.\n",
      "Found 4989 validated image filenames belonging to 1 classes.\n",
      "156/156 [==============================] - 17s 110ms/step\n",
      "156/156 [==============================] - 19s 123ms/step\n",
      "(4989, 2048)   (4989, 2048)\n",
      "Aug %:  0.1  FID:  35512.89\n",
      "Found 5613 validated image filenames belonging to 1 classes.\n",
      "Found 5613 validated image filenames belonging to 1 classes.\n",
      "176/176 [==============================] - 18s 102ms/step\n",
      "176/176 [==============================] - 21s 122ms/step\n",
      "(5613, 2048)   (5613, 2048)\n",
      "Aug %:  0.2  FID:  37304.09\n",
      "Found 6417 validated image filenames belonging to 1 classes.\n",
      "Found 6417 validated image filenames belonging to 1 classes.\n",
      "201/201 [==============================] - 20s 97ms/step\n",
      "201/201 [==============================] - 24s 118ms/step\n",
      "(6417, 2048)   (6417, 2048)\n",
      "Aug %:  0.3  FID:  40212.6\n",
      "Found 4721 validated image filenames belonging to 1 classes.\n",
      "Found 4721 validated image filenames belonging to 1 classes.\n",
      "148/148 [==============================] - 15s 100ms/step\n",
      "148/148 [==============================] - 18s 120ms/step\n",
      "(4721, 2048)   (4721, 2048)\n",
      "Aug %:  0.05  FID:  42214.49\n",
      "Found 4982 validated image filenames belonging to 1 classes.\n",
      "Found 4982 validated image filenames belonging to 1 classes.\n",
      "156/156 [==============================] - 15s 99ms/step\n",
      "156/156 [==============================] - 19s 119ms/step\n",
      "(4982, 2048)   (4982, 2048)\n",
      "Aug %:  0.1  FID:  43087.97\n",
      "Found 5606 validated image filenames belonging to 1 classes.\n",
      "Found 5606 validated image filenames belonging to 1 classes.\n",
      "176/176 [==============================] - 16s 89ms/step\n",
      "176/176 [==============================] - 21s 118ms/step\n",
      "(5606, 2048)   (5606, 2048)\n",
      "Aug %:  0.2  FID:  44848.9\n",
      "Found 6407 validated image filenames belonging to 1 classes.\n",
      "Found 6407 validated image filenames belonging to 1 classes.\n",
      "201/201 [==============================] - 18s 89ms/step\n",
      "201/201 [==============================] - 24s 117ms/step\n",
      "(6407, 2048)   (6407, 2048)\n",
      "Aug %:  0.3  FID:  47797.24\n",
      "Found 5672 validated image filenames belonging to 1 classes.\n",
      "Found 5672 validated image filenames belonging to 1 classes.\n",
      "178/178 [==============================] - 22s 121ms/step\n",
      "178/178 [==============================] - 21s 119ms/step\n",
      "(5672, 2048)   (5672, 2048)\n",
      "Aug %:  0.05  FID:  30853.5\n",
      "Found 5987 validated image filenames belonging to 1 classes.\n",
      "Found 5987 validated image filenames belonging to 1 classes.\n",
      "188/188 [==============================] - 23s 120ms/step\n",
      "188/188 [==============================] - 23s 120ms/step\n",
      "(5987, 2048)   (5987, 2048)\n",
      "Aug %:  0.1  FID:  31249.19\n",
      "Found 6734 validated image filenames belonging to 1 classes.\n",
      "Found 6734 validated image filenames belonging to 1 classes.\n",
      "211/211 [==============================] - 24s 114ms/step\n",
      "211/211 [==============================] - 25s 117ms/step\n",
      "(6734, 2048)   (6734, 2048)\n",
      "Aug %:  0.2  FID:  32245.32\n",
      "Found 7697 validated image filenames belonging to 1 classes.\n",
      "Found 7697 validated image filenames belonging to 1 classes.\n",
      "241/241 [==============================] - 25s 103ms/step\n",
      "241/241 [==============================] - 29s 120ms/step\n",
      "(7697, 2048)   (7697, 2048)\n",
      "Aug %:  0.3  FID:  34112.56\n",
      "Found 6619 validated image filenames belonging to 1 classes.\n",
      "Found 6619 validated image filenames belonging to 1 classes.\n",
      "207/207 [==============================] - 23s 111ms/step\n",
      "207/207 [==============================] - 25s 119ms/step\n",
      "(6619, 2048)   (6619, 2048)\n",
      "Aug %:  0.05  FID:  35761.22\n",
      "Found 6987 validated image filenames belonging to 1 classes.\n",
      "Found 6987 validated image filenames belonging to 1 classes.\n",
      "219/219 [==============================] - 24s 109ms/step\n",
      "219/219 [==============================] - 26s 120ms/step\n",
      "(6987, 2048)   (6987, 2048)\n",
      "Aug %:  0.1  FID:  36625.34\n",
      "Found 7859 validated image filenames belonging to 1 classes.\n",
      "Found 7859 validated image filenames belonging to 1 classes.\n",
      "246/246 [==============================] - 26s 104ms/step\n",
      "246/246 [==============================] - 30s 121ms/step\n",
      "(7859, 2048)   (7859, 2048)\n",
      "Aug %:  0.2  FID:  38884.72\n",
      "Found 8719 validated image filenames belonging to 1 classes.\n",
      "Found 8719 validated image filenames belonging to 1 classes.\n",
      "273/273 [==============================] - 27s 100ms/step\n",
      "273/273 [==============================] - 34s 124ms/step\n",
      "(8719, 2048)   (8719, 2048)\n",
      "Aug %:  0.3  FID:  41142.83\n",
      "Found 2026 validated image filenames belonging to 1 classes.\n",
      "Found 2026 validated image filenames belonging to 1 classes.\n",
      "64/64 [==============================] - 9s 145ms/step\n",
      "64/64 [==============================] - 8s 122ms/step\n",
      "(2026, 2048)   (2026, 2048)\n",
      "Aug %:  0.05  FID:  56636.44\n",
      "Found 2139 validated image filenames belonging to 1 classes.\n",
      "Found 2139 validated image filenames belonging to 1 classes.\n",
      "67/67 [==============================] - 10s 146ms/step\n",
      "67/67 [==============================] - 8s 118ms/step\n",
      "(2139, 2048)   (2139, 2048)\n",
      "Aug %:  0.1  FID:  57239.62\n",
      "Found 2406 validated image filenames belonging to 1 classes.\n",
      "Found 2406 validated image filenames belonging to 1 classes.\n",
      "76/76 [==============================] - 10s 132ms/step\n",
      "76/76 [==============================] - 9s 119ms/step\n",
      "(2406, 2048)   (2406, 2048)\n",
      "Aug %:  0.2  FID:  59130.68\n",
      "Found 2750 validated image filenames belonging to 1 classes.\n",
      "Found 2750 validated image filenames belonging to 1 classes.\n",
      "86/86 [==============================] - 11s 125ms/step\n",
      "86/86 [==============================] - 10s 119ms/step\n",
      "(2750, 2048)   (2750, 2048)\n",
      "Aug %:  0.3  FID:  60707.89\n",
      "{'ASUS': {0.05: 42658.06, 0.1: 43594.0, 0.2: 45688.5, 0.3: 47888.4}, 'IP7P': {0.05: 34143.03, 0.1: 35512.89, 0.2: 37304.09, 0.3: 40212.6}, 'IPP2017': {0.05: 42214.49, 0.1: 43087.97, 0.2: 44848.9, 0.3: 47797.24}, 'SGS8': {0.05: 30853.5, 0.1: 31249.19, 0.2: 32245.32, 0.3: 34112.56}, 'P': {0.05: 35761.22, 0.1: 36625.34, 0.2: 38884.72, 0.3: 41142.83}, 'R': {0.05: 56636.44, 0.1: 57239.62, 0.2: 59130.68, 0.3: 60707.89}}\n"
     ]
    }
   ],
   "source": [
    "train_spoof_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {90} and ground_truth == 'spoof'\")\n",
    "\n",
    "\n",
    "train_real_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {90} and ground_truth == 'real'\")\n",
    "\n",
    "current_train_real_file_path_frame = get_antispoof_frame(train_real_df, dataset_root)\n",
    "\n",
    "#shuffle\n",
    "current_train_real_file_path_frame = current_train_real_file_path_frame.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# test_real_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {75} and ground_truth == 'real'\")\n",
    "#\n",
    "# test_spoof_df = pd.read_csv(os.path.join(dataset_root, dataset_csv_name)).query(f\"subject_number == {75} and ground_truth == 'spoof'\")\n",
    "\n",
    "TRAIN_SPOOF_COMBINATIONS = [\n",
    "         [  \"IP7P\", \"IPP2017\", \"SGS8\"],\n",
    "        [ \"ASUS\",  \"IPP2017\", \"SGS8\"],\n",
    "        [ \"ASUS\", \"IP7P\", \"SGS8\"],\n",
    "    [ \"ASUS\", \"IP7P\", \"IPP2017\"],\n",
    "\n",
    "    [ \"ASUS\", \"IP7P\", \"IPP2017\", \"SGS8\"],\n",
    "    [ \"P\"],\n",
    "]\n",
    "TEST_SPOOF_COMBINATIONS = [\n",
    "    [ \"ASUS\"],\n",
    "    [ \"IP7P\"],\n",
    "    [ \"IPP2017\"],\n",
    "    [ \"SGS8\"],\n",
    "    [ \"P\"],\n",
    "    [ \"ASUS\", \"IP7P\", \"IPP2017\", \"SGS8\"],\n",
    "]\n",
    "aug_name = \"Trad.csv\"\n",
    "\n",
    "use_last_only = False\n",
    "must_remove_normal = True\n",
    "must_use_normal_only=False\n",
    "\n",
    "# aug_root =\"/home/jarred/Documents/Generated/SIW_KF_90\"\n",
    "# aug_csv =\"SIW_KF_90.csv\"\n",
    "aug_root =\"/home/jarred/Documents/TraditionalAugmentation/SIW_90\"\n",
    "aug_csv =\"SIW_90.csv\"\n",
    "aug_frame = pd.read_csv(os.path.join(aug_root, aug_csv))\n",
    "AUG_PERCENTAGES = [0.05,0.1,0.2, 0.30]\n",
    "df_dic = {}\n",
    "for i in range(len(TRAIN_SPOOF_COMBINATIONS)):\n",
    "    train_spoof_combination = TRAIN_SPOOF_COMBINATIONS[i]\n",
    "\n",
    "\n",
    "    current_train_spoof_df = get_category_frame(train_spoof_df,train_spoof_combination)\n",
    "\n",
    "\n",
    "    current_train_spoof_file_path_frame = get_antispoof_frame(current_train_spoof_df, dataset_root)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fid_intra_values ={}\n",
    "    for aug_percentage in AUG_PERCENTAGES:\n",
    "        current_aug_frame = combine_with_augmentation(train_frame= current_train_spoof_file_path_frame, aug_frame= aug_frame,aug_root= aug_root,categories= train_spoof_combination, aug_percentage=aug_percentage,must_remove_normal= must_remove_normal,must_use_normal_only=must_use_normal_only, stratified_name_list_func=None)\n",
    "\n",
    "        current_train_aug_spoof_file_path_frame = pd.concat([current_train_spoof_file_path_frame, current_aug_frame])\n",
    "        current_train_aug_spoof_file_path_frame = current_train_aug_spoof_file_path_frame.sample(frac=1).reset_index(drop=True)\n",
    "        fid = calculate_set_distance(current_train_aug_spoof_file_path_frame, current_train_real_file_path_frame)\n",
    "        fid_intra_values[aug_percentage] = round(fid, 2)\n",
    "        print(\"Aug %: \", aug_percentage, \" FID: \", round(fid, 2))\n",
    "\n",
    "    protocol_name = \"\"\n",
    "    if len(TEST_SPOOF_COMBINATIONS[i]) > 1:\n",
    "        protocol_name = \"R\"\n",
    "    else:\n",
    "        protocol_name = TEST_SPOOF_COMBINATIONS[i][0]\n",
    "\n",
    "    df_dic[protocol_name] = fid_intra_values\n",
    "print(df_dic)\n",
    "df = pd.DataFrame.from_dict(df_dic, orient='index')\n",
    "df.to_csv(aug_name)\n",
    "\n",
    "\n",
    "\n",
    "# spoof_df = get_category_frame(spoof_df, [\"ASUS\", \"IP7P\", \"IPP2017\", \"SGS8\"])\n",
    "# spoof_df = get_category_frame(spoof_df, [ \"IP7P\", \"IPP2017\", \"SGS8\"])\n",
    "# spoof_df = get_category_frame(spoof_df, [\"P\"])\n",
    "# spoof_df = get_category_frame(spoof_df, [\"ASUS\", \"IP7P\", \"IPP2017\"])\n",
    "\n",
    "\n",
    "# test_proto = pd.concat([test_spoof_df, test_real_df])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
